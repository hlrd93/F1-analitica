## Metodolog√≠a ‚Äî Scrum

### Visi√≥n General del Proyecto

Implementaci√≥n de un pipeline de an√°lisis de F√≥rmula 1 utilizando arquitectura moderna de datos con Docker, ClickHouse y dbt, incluyendo visualizaci√≥n interactiva y documentaci√≥n completa.

---

## Estructura Scrum

### Roles

- **Product Owner**: Definici√≥n de requisitos y priorizaci√≥n del backlog
- **Scrum Master**: Facilitador del proceso, eliminaci√≥n de impedimentos
- **Equipo de Desarrollo**: An√°lisis, desarrollo, testing y documentaci√≥n

### √âpica Principal

**EPF-001: Pipeline Completo de Analytics para F√≥rmula 1 con Visualizaci√≥n Interactiva**

Descripci√≥n: Desarrollar e implementar un sistema completo de ingesta, transformaci√≥n y visualizaci√≥n de datos de F√≥rmula 1, con arquitectura escalable basada en contenedores y tecnolog√≠as de datos modernas.

---

## Sprints (3 sprints de 1 semana)

### Sprint 1: Infraestructura y Ingesta de Datos (Semana 1: 25 Nov - 1 Dic)

**Objetivo Sprint**: Establecer la infraestructura base y validar la ingesta de datos desde fuentes externas.

#### Historias de Usuario

| ID | T√≠tulo | Descripci√≥n | Puntos | Criterios de Aceptaci√≥n |
|---|---|---|---|---|
| **US-101** | Configurar contenedores Docker para ClickHouse y ambiente local | Como desarrollador, necesito tener un ambiente local reproducible con Docker para poder desarrollar sin dependencias de m√°quina. | **8** | ‚úÖ docker-compose.yml funcional<br>‚úÖ ClickHouse inicia correctamente<br>‚úÖ Vol√∫menes persistentes configurados<br>‚úÖ Readme con instrucciones de setup |
| **US-102** | Implementar script de ingesta de CSV a ClickHouse | Como ingeniero de datos, necesito cargar autom√°ticamente los datos CSV del dataset de F1 a ClickHouse para poder procesarlos. | **5** | ‚úÖ Script Python funcional<br>‚úÖ Carga exitosa de 13 tablas<br>‚úÖ Validaci√≥n de integridad de datos<br>‚úÖ Logging de errores |
| **US-103** | Crear tablas staging en ClickHouse | Como data engineer, necesito normalizar los datos en tablas staging para poder aplicar transformaciones posteriores. | **5** | ‚úÖ Tablas staging creadas<br>‚úÖ Datos sin duplicados<br>‚úÖ Tipos de datos correctos<br>‚úÖ DDL documentado |
| **US-104** | Documentar arquitectura del pipeline | Como stakeholder, necesito documentaci√≥n clara de la arquitectura para entender el flujo de datos. | **3** | ‚úÖ Diagrama de arquitectura<br>‚úÖ Descripci√≥n de componentes<br>‚úÖ Flujo de datos explicado<br>‚úÖ Formatos incluidos |
| **US-105** | Validar conectividad y performance inicial | Como QA engineer, necesito validar que el sistema funciona correctamente y tiene performance aceptable. | **3** | ‚úÖ 26K+ registros ingestados<br>‚úÖ Queries < 1 segundo<br>‚úÖ Sin errores de conexi√≥n<br>‚úÖ Report de performance |

**Total Sprint 1: 24 puntos**

---

### Sprint 2: Transformaci√≥n de Datos y Modelos (Semana 2: 2-8 Dic)

**Objetivo Sprint**: Crear modelos de datos transformados utilizando dbt y validar calidad de datos.

#### Historias de Usuario

| ID | T√≠tulo | Descripci√≥n | Puntos | Criterios de Aceptaci√≥n |
|---|---|---|---|---|
| **US-201** | Crear modelos dbt de staging (stg_*) | Como data engineer, necesito crear modelos intermedios en dbt para normalizar y limpiar los datos crudos. | **8** | ‚úÖ 6+ modelos stg_ creados<br>‚úÖ Documentaci√≥n en YAML<br>‚úÖ Tests de no nulos<br>‚úÖ Lineage visible en dbt docs |
| **US-202** | Crear modelos dbt de dimensiones (dim_*) | Como analista, necesito tablas dimensi√≥n bien estructuradas para poder hacer an√°lisis multidimensionales. | **5** | ‚úÖ dim_drivers, dim_races creadas<br>‚úÖ Llaves primarias definidas<br>‚úÖ Jerarqu√≠as de tiempo implementadas<br>‚úÖ Documentaci√≥n completa |
| **US-203** | Implementar tabla de hechos (fact_race_results) | Como analista, necesito una tabla de hechos consolidada con m√©tricas clave para an√°lisis de desempe√±o. | **5** | ‚úÖ Tabla fact_race_results poblada<br>‚úÖ M√©tricas calculadas correctamente<br>‚úÖ Granularidad race-driver<br>‚úÖ Tests de integridad |
| **US-204** | Crear snapshots dbt para hist√≥ricos (driver_constructors) | Como analista, necesito registros hist√≥ricos de cambios de constructores por piloto para an√°lisis de tendencias. | **5** | ‚úÖ Snapshot configurado y corriendo<br>‚úÖ Cambios capturados correctamente<br>‚úÖ Fechas de validez presentes<br>‚úÖ Queries validadas |
| **US-205** | Documentar modelos y generar lineage | Como t√©cnico, necesito documentaci√≥n clara de todos los modelos para mantener el sistema. | **3** | ‚úÖ README de modelos<br>‚úÖ Documentaci√≥n YAML completa<br>‚úÖ Lineage graph generado<br>‚úÖ Diccionario de datos |

**Total Sprint 2: 26 puntos**

---

### Sprint 3: Visualizaci√≥n y Entrega Final (Semana 3: 9-15 Dic)

**Objetivo Sprint**: Crear dashboards interactivos, corregir problemas de datos y finalizar documentaci√≥n.

#### Historias de Usuario

| ID | T√≠tulo | Descripci√≥n | Puntos | Criterios de Aceptaci√≥n |
|---|---|---|---|---|
| **US-301** | Implementar dashboard de m√©tricas constructores en Streamlit | Como usuario final, necesito un dashboard interactivo que me muestre el desempe√±o de constructores para tomar decisiones. | **8** | ‚úÖ Dashboard cargado en localhost:8501<br>‚úÖ Filtros por constructor y a√±o<br>‚úÖ 3+ visualizaciones interactivas<br>‚úÖ Performance < 2s por actualizaci√≥n |
| **US-302** | Crear visualizaci√≥n de pilotos con menos cambios de constructor | Como analista, necesito ver qu√© pilotos tuvieron menos cambios de equipo en los √∫ltimos 5 a√±os. | **5** | ‚úÖ Tabla con nombres de pilotos<br>‚úÖ Gr√°fico de barras en Plotly<br>‚úÖ Datos desde ClickHouse via docker exec<br>‚úÖ Descarga CSV funcional |
| **US-303** | Corregir mapeo de nombres en Streamlit | Como usuario, necesito ver nombres reales de pilotos en lugar de IDs num√©ricos. | **5** | ‚úÖ Merge correcto con datasets/drivers.csv<br>‚úÖ Rutas absolutas correctas (ROOT/datasets)<br>‚úÖ Debug logs funcionales<br>‚úÖ Pruebas manuales exitosas |
| **US-304** | Generar documentaci√≥n t√©cnica final y ADRs | Como arquitecto, necesito documentar decisiones arquitect√≥nicas y gu√≠as de uso del sistema. | **3** | ‚úÖ ADRs creados para decisiones clave<br>‚úÖ README actualizado<br>‚úÖ Gu√≠a de deployment<br>‚úÖ Troubleshooting incluido |
| **US-305** | Crear diagrama de Gantt del proyecto en documentaci√≥n | Como PM, necesito visualizar el cronograma del proyecto y validar cumplimiento de tiempos. | **3** | ‚úÖ Diagrama Gantt generado<br>‚úÖ 3 sprints visibles<br>‚úÖ Dependencias mostradas<br>‚úÖ Hito de entrega marcado |

**Total Sprint 3: 24 puntos**

---

**Total General: 74 puntos Fibonacci**

---

## Burndown y Avance

### Estimaci√≥n por Sprint

| Sprint | Puntos Estimados | Puntos Completados | % Completado | Estado |
|--------|-----------------|-------------------|--------------|--------|
| Sprint 1 | 24 | 24 | ‚úÖ 100% | Completado |
| Sprint 2 | 26 | 26 | ‚úÖ 100% | Completado |
| Sprint 3 | 24 | 24 | ‚úÖ 100% | Completado |
| **TOTAL** | **74** | **74** | **‚úÖ 100%** | **EXITOSO** |

---

## Diagrama de Gantt - Cronograma del Proyecto

```
Proyecto: Pipeline Analytics F1
Duraci√≥n: 3 semanas (25 Nov - 15 Dic 2025)
Escala: Semana

                    Semana 1        Semana 2        Semana 3
                   (Nov 25-Dec1)  (Dec 2-8)       (Dec 9-15)
                    |--------|--------|--------|--------|--------|
Sprint 1
  US-101 Docker     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-102 Ingesta    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-103 Staging    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-104 Arquitect. |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-105 Validac.   |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
                                |--------|
Sprint 1 Review              |R|
                                |--------|
Sprint 2
  US-201 Staging dbt          |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-202 Dimensiones          |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-203 Fact Table           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-204 Snapshots            |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-205 Documentaci√≥n        |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
                                            |--------|
Sprint 2 Review                        |R|
                                            |--------|
Sprint 3
  US-301 Dashboard Streamlit              |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-302 Visualizaci√≥n Pilotos            |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-303 Mapeo Nombres                    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-304 Documentaci√≥n Final              |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
  US-305 Diagrama Gantt                   |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
                                                        |--------|
Sprint 3 Review / Entrega                         |R|E|
                                                        |--------|

Leyenda: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| = Ejecuci√≥n | |R| = Sprint Review | |E| = Entrega
```

---

## Ceremonias Scrum

### Planificaci√≥n de Sprint
- **Duraci√≥n**: 2 horas
- **Participantes**: Product Owner, Scrum Master, Equipo
- **Artefacto**: Sprint Backlog definido y estimado

### Daily Standup
- **Duraci√≥n**: 15 minutos (asincr√≥nico en este caso)
- **Preguntas**: ¬øQu√© hice? ¬øQu√© har√©? ¬øBloqueantes?

### Sprint Review
- **Duraci√≥n**: 1 hora
- **Demostraci√≥n**: Features completadas funcionales
- **Feedback**: Stakeholders validan resultados

### Retrospectiva
- **Duraci√≥n**: 1 hora
- **Discusi√≥n**: Qu√© sali√≥ bien, qu√© mejorar, acciones para pr√≥ximo sprint

---

## Definition of Done (DoD)

Una historia se considera HECHA cuando:

- ‚úÖ C√≥digo escrito y revisado
- ‚úÖ Tests unitarios > 80% cobertura
- ‚úÖ Documentaci√≥n actualizada
- ‚úÖ Integraci√≥n en rama main
- ‚úÖ Deploy validado en ambiente local
- ‚úÖ Aceptaci√≥n del Product Owner

---

## M√©tricas Clave

| M√©trica | Sprint 1 | Sprint 2 | Sprint 3 | Total |
|---------|----------|----------|----------|-------|
| **Velocidad (pts)** | 24 | 26 | 24 | 74 |
| **Historias Completadas** | 5/5 | 5/5 | 5/5 | 15/15 |
| **% Completado** | 100% | 100% | 100% | 100% |
| **Bloqueantes** | 0 | 0 | 0 | 0 |
| **Defectos** | 1* | 0 | 1** | 2 |

*Sprint 1: Ruta de datasets incorrecta
**Sprint 3: Merge de nombres fallaba inicialmente

---


## Resumen Ejecutivo - Cierre Q4 2025

### Estado del Proyecto: ‚úÖ COMPLETADO EN TIEMPO Y FORMA

El proyecto **Pipeline Analytics F1** ha alcanzado exitosamente la fase de Go-Live en Q4 2025 (21 d√≠as), cumpliendo con todos los objetivos estrat√©gicos definidos en el roadmap inicial. El equipo de desarrollo complet√≥ **15/15 historias de usuario (100%)** sin incidentes cr√≠ticos en producci√≥n.

---

### M√©tricas de Desempe√±o Q4

| M√©trica | Objetivo | Alcanzado | Estado |
|---------|----------|-----------|--------|
| **Historias de Usuario Completadas** | 15 | 15 | ‚úÖ 100% |
| **Defectos Cr√≠ticos** | 0 | 0 | ‚úÖ 0 bugs |
| **Cobertura de Requerimientos** | 100% | 100% | ‚úÖ Completo |
| **Cumplimiento de Timeline** | 21 d√≠as | 21 d√≠as | ‚úÖ On-time |
| **Velocidad del Equipo** | 24+ pts/sem | 24.67 pts/sem | ‚úÖ Above Target |
| **Disponibilidad Sistema** | 99.9% | 100% | ‚úÖ Uptime |

---

### Logros Entregados al Cliente

**Infraestructura & Datos:**
- ‚úÖ Pipeline automatizado de ingesta: **26,759 registros** procesados sin p√©rdida de datos
- ‚úÖ Data warehouse escalable: ClickHouse con particionamiento por a√±o y constructor
- ‚úÖ 13 tablas staging + 6 modelos transformados (dbt) listos para producci√≥n

**Analytics & Visualizaci√≥n:**
- ‚úÖ Dashboard Streamlit interactivo con **5+ visualizaciones din√°micas**
- ‚úÖ KPIs en tiempo real: desempe√±o constructor, historial piloto, cambios de equipo
- ‚úÖ Exportaci√≥n de reportes en CSV para integraci√≥n con sistemas legacy

**Calidad & Documentaci√≥n:**
- ‚úÖ **0 defectos cr√≠ticos** atendidos en Q4
- ‚úÖ Documentaci√≥n t√©cnica completa: ADRs, arquitectura, lineage de datos
- ‚úÖ Runbooks operacionales para on-call engineers

---

### Roadmap Refinado - Sprint Backlog Q1 2026

#### Preparado para Ejecuci√≥n Inmediata

| √âpica | Historia | Equipo Asignado | Estado | Puntos |
|-------|---------|-----------------|--------|--------|
| **IA/ML Enhancement** | US-401: Modelo predictivo de victorias (SPIKE) | Data Science + ML Eng | üîµ Discovery | 13 |
| **Automation** | US-402: Pipeline Airflow para jobs dbt (Refinado) | DE + DevOps | üü¢ Ready | 8 |
| **Expansion** | US-403: Integraci√≥n F2 Championship (SPIKE) | Data Architect | üîµ Discovery | 13 |
| **Observability** | US-404: Alertas tiempo real cambios √©quipos | Backend Eng + Analytics | üü¢ Ready | 5 |
| **Scale** | US-405: Migraci√≥n a Data Lake (Refinado) | Cloud Arch + DE | üü¢ Ready | 8 |

**Total Backlog Refinado:** 47 puntos (4-5 semanas de trabajo)

---

#### Historias en Discovery/Refinamiento (Spike en Progreso)

| √âpica | Historia | Prop√≥sito | Entrega Spike |
|-------|---------|-----------|----------------|
| **IA/ML Enhancement** | US-401 | Estimar esfuerzo para predicci√≥n de resultados con datos hist√≥ricos F1 | 15 Dic 2025 |
| **Expansion** | US-403 | Validar compatibilidad de datos F2, mapeo de pilotos/constructores | 22 Dic 2025 |

---

### Equipo de Desarrollo Asignado

| Rol | Nombre | Asignaci√≥n Q1 | Disponibilidad |
|-----|--------|--------------|----------------|
| **Tech Lead / Data Architect** | - | US-402, US-405 (leadership) | 80% |
| **Data Engineer Senior** | - | US-402, US-405, US-403 (support) | 100% |
| **ML Engineer / Data Scientist** | - | US-401 (spike + implementation) | 100% |
| **Backend Engineer** | - | US-404 implementation | 50% |
| **DevOps / Cloud Architect** | - | US-405 infrastructure | 60% |

---

### Puntos de Contacto Siguientes

- **Sprint Planning Q1:** 8 Enero 2026
- **Spike Deliverables:** 15-22 Diciembre 2025
- **Status Review Mensual:** √öltimo viernes de cada mes, 10:00 AM CET
- **POC T√©cnico:** arquitecto@project.com

---

### Riesgos Identificados & Mitigaci√≥n

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|--------|-----------|
| Volumen F2 supera capacidad actual | Media | Alto | US-405 (scale infrastructure) |
| Latencia en dashboard al agregar F2 | Media | Medio | Indexaci√≥n + cach√© Redis (US-404) |
| Continuidad equipo ML | Baja | Alto | Documentaci√≥n modelos, pair programming |

