# ğŸï¸ F1 Analytics Pipeline

> Pipeline de anÃ¡lisis de datos de FÃ³rmula 1 con ClickHouse, dbt y Streamlit

[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://www.docker.com/)
[![dbt](https://img.shields.io/badge/dbt-Powered-orange)](https://www.getdbt.com/)
[![ClickHouse](https://img.shields.io/badge/ClickHouse-OLAP-yellow)](https://clickhouse.com/)
[![Python](https://img.shields.io/badge/Python-3.9+-green)](https://www.python.org/)

## ğŸ¯ DescripciÃ³n

Pipeline de datos moderno para anÃ¡lisis de FÃ³rmula 1, diseÃ±ado con arquitectura ELT (Extract, Load, Transform) usando ClickHouse como base de datos OLAP columnar y dbt para transformaciones SQL. Incluye dashboards interactivos con Streamlit.

**CaracterÃ­sticas principales:**
- ğŸ—„ï¸ **ClickHouse** - Base de datos columnar OLAP de alto rendimiento
- ğŸ”„ **dbt** - Transformaciones SQL con tests y documentaciÃ³n
- ğŸ³ **Docker** - Despliegue containerizado
- ğŸ“Š **Streamlit** - Dashboards interactivos
- ğŸ“¸ **Snapshots** - SCD Type 2 para historial de dimensiones
- âœ… **Calidad de datos** - Tests automatizados con dbt

## ğŸ—ï¸ Arquitectura

Pipeline de datos implementado con tecnologÃ­as modernas:

```mermaid
flowchart LR
    A[CSV Files] --> B[Python Ingestion]
    B --> C[ClickHouse Raw]
    C --> D[dbt Transformations]
    D --> E[ClickHouse Analytics]
    E --> F[Streamlit Dashboard]
```

**Stack tecnolÃ³gico:**
- **Base de datos:** ClickHouse (OLAP columnar de alto rendimiento)
- **TransformaciÃ³n:** dbt (Data Build Tool)
- **OrquestaciÃ³n:** Docker Compose
- **VisualizaciÃ³n:** Streamlit
- **AnÃ¡lisis:** Pandas

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

```bash
# Docker y Docker Compose instalados
docker --version
docker-compose --version

# Conda (opcional, para desarrollo local)
conda --version
```

### InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone https://github.com/hlrd93/F1-analitica.git
cd F1-analitica
```

2. **Configurar variables de entorno:**
```bash
# Crear archivo .env en scripts/
cat > scripts/.env << EOF
CLICKHOUSE_HOST=clickhouse
CLICKHOUSE_PORT=9000
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=
EOF
```

3. **Levantar ClickHouse:**
```bash
docker-compose up -d clickhouse
```

4. **Ingestar datos:**
```bash
# OpciÃ³n 1: Script Python (recomendado)
python scripts/load_csvs_to_clickhouse.py

# OpciÃ³n 2: Script Shell
bash scripts/ingest_csvs_with_docker.sh
```

5. **Ejecutar transformaciones dbt:**
```bash
docker-compose up dbt-runner
```

6. **Lanzar dashboard:**
```bash
cd streamlit_app
streamlit run constructor_dashboard.py
```

## ğŸ“Š Estructura del Proyecto

```
F1/
â”œâ”€â”€ datasets/               # CSV fuente de datos F1
â”‚   â”œâ”€â”€ circuits.csv
â”‚   â”œâ”€â”€ races.csv
â”‚   â”œâ”€â”€ drivers.csv
â”‚   â”œâ”€â”€ constructors.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/               # Scripts de ingesta
â”‚   â”œâ”€â”€ load_csvs_to_clickhouse.py
â”‚   â””â”€â”€ ingest_csvs_with_docker.sh
â”œâ”€â”€ dbt_project/          # Modelos dbt
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/      # Modelos fuente
â”‚   â”‚   â”œâ”€â”€ dim/          # Dimensiones
â”‚   â”‚   â”œâ”€â”€ fact/         # Hechos
â”‚   â”‚   â””â”€â”€ marts/        # Data marts
â”‚   â””â”€â”€ snapshots/        # Snapshots SCD Type 2
â”œâ”€â”€ streamlit_app/        # Dashboard interactivo
â”‚   â””â”€â”€ constructor_dashboard.py
â”œâ”€â”€ docs/                 # DocumentaciÃ³n MkDocs
â””â”€â”€ docker-compose.yml    # OrquestaciÃ³n de servicios
```

## ğŸ”„ Pipeline de Datos

### 1. Ingesta (Raw Layer)

Los datos CSV se cargan a ClickHouse en el schema `raw`:

```python
# scripts/load_csvs_to_clickhouse.py
# - Lee CSVs del directorio datasets/
# - Crea tablas raw.raw_<nombre>
# - Maneja valores nulos (\\N)
# - Carga por lotes (BATCH_SIZE=10000)
```

**Tablas raw disponibles:**
- `raw.raw_circuits`
- `raw.raw_races`
- `raw.raw_drivers`
- `raw.raw_constructors`
- `raw.raw_results`
- `raw.raw_constructor_results`
- Y mÃ¡s...

### 2. TransformaciÃ³n (Analytics Layer)

dbt transforma los datos raw en modelos analÃ­ticos:

```sql
-- dbt_project/models/staging/stg_races.sql
-- dbt_project/models/dim/dim_fecha.sql
-- dbt_project/models/fact/fact_race_results.sql
```

**CaracterÃ­sticas:**
- âœ… Modelado dimensional (Star Schema)
- âœ… Tests de calidad de datos
- âœ… DocumentaciÃ³n en `schema.yml`
- âœ… Snapshots SCD Type 2 para historial

### 3. VisualizaciÃ³n

Dashboard Streamlit con anÃ¡lisis interactivo de constructores.

## ğŸ“š DocumentaciÃ³n

La documentaciÃ³n completa estÃ¡ disponible en formato MkDocs:

```bash
# Instalar dependencias
pip install mkdocs-material

# Servir localmente
mkdocs serve

# Abrir en navegador
open http://localhost:8000
```

**Contenido de la documentaciÃ³n:**
- ğŸ—ï¸ [Arquitectura](docs/architecture.md) - Diagrama del pipeline
- ğŸ”§ [ImplementaciÃ³n](docs/implementation.md) - Referencias al cÃ³digo
- ğŸ“Š [MetodologÃ­a](docs/metodologia.md) - Enfoque analÃ­tico
- ğŸ’‰ [Ingesta](docs/ingestion.md) - Proceso de carga
- ğŸ“¸ [Snapshots](docs/snapshots.md) - SCD Type 2
- ğŸ¯ [Casos de uso](docs/use_case.md) - Ejemplos prÃ¡cticos
- ğŸ“‹ [ADR](docs/adr/) - Decisiones de arquitectura

## ğŸ› ï¸ Desarrollo

### Entorno Conda

```bash
# Crear entorno
conda env create -f environment.yml

# Activar
conda activate f1-analytics

# Actualizar
conda env update -f environment.yml --prune
```

### Comandos Ãºtiles

```bash
# Ver logs de ClickHouse
docker-compose logs -f clickhouse

# Conectar a ClickHouse CLI
docker exec -it clickhouse clickhouse-client

# Ejecutar consultas SQL
docker exec -it clickhouse clickhouse-client --query "SELECT * FROM analytics.fact_race_results LIMIT 10"

# Ejecutar un modelo dbt especÃ­fico
docker-compose run dbt-runner dbt run --select dim_fecha

# Ejecutar tests dbt
docker-compose run dbt-runner dbt test
```

## ğŸ“Š AnÃ¡lisis Exploratorio

El proyecto incluye anÃ¡lisis EDA detallado:

```bash
# Generar reporte EDA
python scripts/eda_pandas.py

# Ver reporte
cat datasets/eda_report.md
```

El reporte incluye:
- EstadÃ­sticas descriptivas
- Valores faltantes
- Distribuciones
- Valores Ãºnicos
- Top valores categÃ³ricos

## ğŸ“ Contexto AcadÃ©mico

Proyecto desarrollado para la MaestrÃ­a en Ciencia de Datos de UCU.

**Requisitos cumplidos:**
- âœ… Modelado dimensional (Star Schema)
- âœ… Procesos ETL/ELT
- âœ… Dashboards de Business Intelligence
- âœ… GestiÃ³n de calidad de datos
- âœ… DocumentaciÃ³n completa
- âœ… Snapshots para dimensiones lentamente cambiantes

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico, pero el feedback es bienvenido. Para contribuir:

1. Fork el repositorio
2. Crea una rama feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT.

## ğŸ‘¤ Autor

**Herwin** - MaestrÃ­a en Ciencia de Datos, UCU

ğŸ™ [GitHub](https://github.com/hlrd93)

---

<p align="center">
  <sub>â­ Si este proyecto te resulta Ãºtil, dale una estrella!</sub>
</p>
